#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSON Difference Analysis Tool
åˆ†æç”Ÿæˆçš„ .skel.json æ–‡ä»¶ä¸åŸå§‹ .json æ–‡ä»¶ä¹‹é—´çš„å·®å¼‚

Usage:
    python analyze_json_differences.py
    python analyze_json_differences.py --data-dir custom_data
    python analyze_json_differences.py --tolerance 0.05 --abs-tolerance 0.001
    python analyze_json_differences.py --output diff_report.txt
"""

import os
import sys
import argparse
import time
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional
import subprocess
import json


class JsonDifferenceAnalyzer:
    def __init__(self, data_dir: str = "../data", tolerance: float = 0.10, 
                 abs_tolerance: float = 0.01, ignore_defaults: bool = True):
        self.data_dir = Path(data_dir).resolve()
        self.tolerance = tolerance
        self.abs_tolerance = abs_tolerance
        self.ignore_defaults = ignore_defaults
        
        # ç¡®ä¿ json_diff.py è·¯å¾„æ­£ç¡®
        self.json_diff_script = Path(__file__).parent / "json_diff.py"
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_pairs': 0,
            'identical_files': 0,
            'different_files': 0,
            'missing_original_files': 0,
            'missing_generated_files': 0,
            'error_files': 0,
            'total_time': 0.0,
            'analysis_results': []
        }
    
    def check_prerequisites(self) -> bool:
        """æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶å’Œç›®å½•æ˜¯å¦å­˜åœ¨"""
        if not self.data_dir.exists():
            print(f"âŒ é”™è¯¯: dataç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
            return False
        
        if not self.json_diff_script.exists():
            print(f"âŒ é”™è¯¯: json_diff.pyä¸å­˜åœ¨: {self.json_diff_script}")
            return False
        
        return True
    
    def find_json_file_pairs(self) -> List[Tuple[Path, Path]]:
        """æŸ¥æ‰¾ .skel.json å’Œå¯¹åº”çš„ .json æ–‡ä»¶å¯¹"""
        pairs = []
        
        # æŸ¥æ‰¾æ‰€æœ‰ .skel.json æ–‡ä»¶
        for skel_json_file in self.data_dir.rglob("*.skel.json"):
            if skel_json_file.is_file():
                # æ¨æ–­å¯¹åº”çš„åŸå§‹ .json æ–‡ä»¶è·¯å¾„
                # ä¾‹å¦‚: data/42/cloud-pot/export/cloud-pot.skel.json 
                #   -> data/42/cloud-pot/export/cloud-pot.json
                original_json_file = skel_json_file.with_suffix('').with_suffix('.json')
                
                pairs.append((skel_json_file, original_json_file))
        
        return sorted(pairs)
    
    def analyze_file_pair(self, skel_json_path: Path, original_json_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶å¯¹çš„å·®å¼‚"""
        result = {
            'skel_json_path': skel_json_path,
            'original_json_path': original_json_path,
            'status': 'unknown',
            'differences_count': 0,
            'ignored_defaults_count': 0,
            'analysis_time': 0.0,
            'error_message': '',
            'diff_output': ''
        }
        
        start_time = time.time()
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not skel_json_path.exists():
                result['status'] = 'missing_generated'
                result['error_message'] = f"ç”Ÿæˆçš„æ–‡ä»¶ä¸å­˜åœ¨: {skel_json_path}"
                return result
            
            if not original_json_path.exists():
                result['status'] = 'missing_original'
                result['error_message'] = f"åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨: {original_json_path}"
                return result
            
            # è°ƒç”¨ json_diff.py è¿›è¡Œæ¯”è¾ƒ
            cmd = [
                sys.executable,
                str(self.json_diff_script),
                str(skel_json_path),
                str(original_json_path),
                '--tolerance', str(self.tolerance),
                '--abs-tolerance', str(self.abs_tolerance),
                '--format', 'simple'
            ]
            
            if not self.ignore_defaults:
                cmd.append('--no-ignore-defaults')
            
            process = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60,
                cwd=self.json_diff_script.parent
            )
            
            result['analysis_time'] = time.time() - start_time
            result['diff_output'] = process.stdout
            
            # è§£æè¾“å‡ºç»“æœ
            if process.returncode == 0:
                # æ–‡ä»¶ç›¸åŒæˆ–åœ¨æ„ä¹‰ä¸Šç›¸åŒ
                result['status'] = 'identical'
                result['differences_count'] = 0
                
                # å°è¯•æå–å¿½ç•¥çš„é»˜è®¤å€¼æ•°é‡
                if "å·²å¿½ç•¥" in process.stdout:
                    import re
                    match = re.search(r'å·²å¿½ç•¥ (\d+) ä¸ªé»˜è®¤å€¼å·®å¼‚', process.stdout)
                    if match:
                        result['ignored_defaults_count'] = int(match.group(1))
            else:
                # æ–‡ä»¶æœ‰å·®å¼‚
                result['status'] = 'different'
                
                # å°è¯•æå–å·®å¼‚æ•°é‡
                import re
                match = re.search(r'å‘ç° (\d+) ä¸ªå·®å¼‚', process.stdout)
                if match:
                    result['differences_count'] = int(match.group(1))
                
                # å°è¯•æå–å¿½ç•¥çš„é»˜è®¤å€¼æ•°é‡
                match = re.search(r'å·²å¿½ç•¥ (\d+) ä¸ªé»˜è®¤å€¼å·®å¼‚', process.stdout)
                if match:
                    result['ignored_defaults_count'] = int(match.group(1))
                
        except subprocess.TimeoutExpired:
            result['status'] = 'error'
            result['error_message'] = "åˆ†æè¶…æ—¶ (60ç§’)"
            result['analysis_time'] = time.time() - start_time
        except Exception as e:
            result['status'] = 'error'
            result['error_message'] = f"åˆ†æé”™è¯¯: {str(e)}"
            result['analysis_time'] = time.time() - start_time
        
        return result
    
    def analyze_all(self) -> None:
        """åˆ†ææ‰€æœ‰æ–‡ä»¶å¯¹"""
        print("=== Spine JSON å·®å¼‚åˆ†æå™¨ ===")
        print(f"æ•°æ®ç›®å½•: {self.data_dir}")
        print(f"æ•°å€¼å®¹å·®: {self.tolerance*100:.1f}%")
        print(f"ç»å¯¹å®¹å·®: {self.abs_tolerance}")
        print(f"å¿½ç•¥é»˜è®¤å€¼: {'æ˜¯' if self.ignore_defaults else 'å¦'}")
        print("=" * 60)
        
        if not self.check_prerequisites():
            return
        
        file_pairs = self.find_json_file_pairs()
        if not file_pairs:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½• .skel.json æ–‡ä»¶")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œ convert_skel_to_json.py ç”Ÿæˆ JSON æ–‡ä»¶")
            return
        
        self.stats['total_pairs'] = len(file_pairs)
        print(f"æ‰¾åˆ° {len(file_pairs)} ä¸ªæ–‡ä»¶å¯¹")
        print("-" * 60)
        
        overall_start = time.time()
        
        for i, (skel_json_path, original_json_path) in enumerate(file_pairs, 1):
            # è·å–ç›¸å¯¹è·¯å¾„ç”¨äºæ˜¾ç¤º
            rel_path = skel_json_path.relative_to(self.data_dir)
            print(f"[{i:3d}/{len(file_pairs)}] {rel_path}")
            
            result = self.analyze_file_pair(skel_json_path, original_json_path)
            self.stats['analysis_results'].append(result)
            
            # æ›´æ–°ç»Ÿè®¡
            if result['status'] == 'identical':
                print(f"           âœ… æ–‡ä»¶ç›¸åŒ ({result['analysis_time']:.3f}s)")
                if result['ignored_defaults_count'] > 0:
                    print(f"           ğŸ’¡ å¿½ç•¥äº† {result['ignored_defaults_count']} ä¸ªé»˜è®¤å€¼å·®å¼‚")
                self.stats['identical_files'] += 1
                
            elif result['status'] == 'different':
                print(f"           âš ï¸  æœ‰å·®å¼‚ ({result['analysis_time']:.3f}s)")
                print(f"           å‘ç° {result['differences_count']} ä¸ªå·®å¼‚")
                if result['ignored_defaults_count'] > 0:
                    print(f"           å¿½ç•¥äº† {result['ignored_defaults_count']} ä¸ªé»˜è®¤å€¼å·®å¼‚")
                self.stats['different_files'] += 1
                
            elif result['status'] == 'missing_original':
                print(f"           âŒ ç¼ºå°‘åŸå§‹æ–‡ä»¶")
                self.stats['missing_original_files'] += 1
                
            elif result['status'] == 'missing_generated':
                print(f"           âŒ ç¼ºå°‘ç”Ÿæˆæ–‡ä»¶")
                self.stats['missing_generated_files'] += 1
                
            else:  # error
                print(f"           ğŸ’¥ åˆ†æé”™è¯¯ ({result['analysis_time']:.3f}s)")
                print(f"           é”™è¯¯: {result['error_message']}")
                self.stats['error_files'] += 1
        
        self.stats['total_time'] = time.time() - overall_start
        self.print_summary()
    
    def print_summary(self) -> None:
        """æ‰“å°åˆ†æç»Ÿè®¡æ‘˜è¦"""
        print("=" * 60)
        print("=== å·®å¼‚åˆ†ææ‘˜è¦ ===")
        print(f"æ€»æ–‡ä»¶å¯¹æ•°: {self.stats['total_pairs']}")
        print(f"å®Œå…¨ç›¸åŒ: {self.stats['identical_files']}")
        print(f"å­˜åœ¨å·®å¼‚: {self.stats['different_files']}")
        print(f"ç¼ºå°‘åŸå§‹æ–‡ä»¶: {self.stats['missing_original_files']}")
        print(f"ç¼ºå°‘ç”Ÿæˆæ–‡ä»¶: {self.stats['missing_generated_files']}")
        print(f"åˆ†æé”™è¯¯: {self.stats['error_files']}")
        
        if self.stats['total_pairs'] > 0:
            identical_rate = self.stats['identical_files'] / self.stats['total_pairs'] * 100
            print(f"ç›¸åŒç‡: {identical_rate:.1f}%")
        
        print(f"æ€»è€—æ—¶: {self.stats['total_time']:.3f}s")
        
        # æ˜¾ç¤ºæœ‰å·®å¼‚çš„æ–‡ä»¶åˆ—è¡¨
        different_files = [r for r in self.stats['analysis_results'] if r['status'] == 'different']
        if different_files:
            print("\n=== å­˜åœ¨å·®å¼‚çš„æ–‡ä»¶ ===")
            for result in different_files:
                rel_path = result['skel_json_path'].relative_to(self.data_dir)
                print(f"âš ï¸  {rel_path} ({result['differences_count']} ä¸ªå·®å¼‚)")
        
        # æ˜¾ç¤ºé”™è¯¯æ–‡ä»¶åˆ—è¡¨
        error_files = [r for r in self.stats['analysis_results'] if r['status'] in ['error', 'missing_original', 'missing_generated']]
        if error_files:
            print("\n=== é”™è¯¯æ–‡ä»¶åˆ—è¡¨ ===")
            for result in error_files:
                rel_path = result['skel_json_path'].relative_to(self.data_dir)
                print(f"âŒ {rel_path}: {result['error_message']}")
        
        # æœ€ç»ˆçŠ¶æ€
        if self.stats['different_files'] == 0 and self.stats['error_files'] == 0:
            print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶åˆ†æå®Œæˆï¼Œè½¬æ¢è´¨é‡è‰¯å¥½!")
        elif self.stats['identical_files'] > 0:
            print(f"\nâš ï¸  éƒ¨åˆ†æ–‡ä»¶å­˜åœ¨å·®å¼‚æˆ–é”™è¯¯ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°ä¿¡æ¯")
        else:
            print(f"\nğŸ’¥ è½¬æ¢è´¨é‡ä¸ä½³ï¼Œè¯·æ£€æŸ¥è½¬æ¢è¿‡ç¨‹å’Œå·¥å…·")
    
    def save_detailed_report(self, output_path: str) -> None:
        """ä¿å­˜è¯¦ç»†çš„å·®å¼‚æŠ¥å‘Š"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("Spine JSON å·®å¼‚åˆ†æè¯¦ç»†æŠ¥å‘Š\n")
                f.write("=" * 60 + "\n\n")
                
                f.write(f"åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ•°æ®ç›®å½•: {self.data_dir}\n")
                f.write(f"æ•°å€¼å®¹å·®: {self.tolerance*100:.1f}%\n")
                f.write(f"ç»å¯¹å®¹å·®: {self.abs_tolerance}\n")
                f.write(f"å¿½ç•¥é»˜è®¤å€¼: {'æ˜¯' if self.ignore_defaults else 'å¦'}\n\n")
                
                # ç»Ÿè®¡æ‘˜è¦
                f.write("ç»Ÿè®¡æ‘˜è¦:\n")
                f.write("-" * 30 + "\n")
                f.write(f"æ€»æ–‡ä»¶å¯¹æ•°: {self.stats['total_pairs']}\n")
                f.write(f"å®Œå…¨ç›¸åŒ: {self.stats['identical_files']}\n")
                f.write(f"å­˜åœ¨å·®å¼‚: {self.stats['different_files']}\n")
                f.write(f"ç¼ºå°‘åŸå§‹æ–‡ä»¶: {self.stats['missing_original_files']}\n")
                f.write(f"ç¼ºå°‘ç”Ÿæˆæ–‡ä»¶: {self.stats['missing_generated_files']}\n")
                f.write(f"åˆ†æé”™è¯¯: {self.stats['error_files']}\n\n")
                
                # è¯¦ç»†ç»“æœ
                f.write("è¯¦ç»†åˆ†æç»“æœ:\n")
                f.write("-" * 30 + "\n")
                
                for result in self.stats['analysis_results']:
                    rel_path = result['skel_json_path'].relative_to(self.data_dir)
                    f.write(f"\næ–‡ä»¶: {rel_path}\n")
                    f.write(f"çŠ¶æ€: {result['status']}\n")
                    f.write(f"åˆ†ææ—¶é—´: {result['analysis_time']:.3f}s\n")
                    
                    if result['status'] == 'different':
                        f.write(f"å·®å¼‚æ•°é‡: {result['differences_count']}\n")
                        f.write(f"å¿½ç•¥é»˜è®¤å€¼: {result['ignored_defaults_count']}\n")
                        f.write("å·®å¼‚è¯¦æƒ…:\n")
                        f.write(result['diff_output'])
                        f.write("\n")
                    elif result['status'] == 'identical':
                        if result['ignored_defaults_count'] > 0:
                            f.write(f"å¿½ç•¥é»˜è®¤å€¼: {result['ignored_defaults_count']}\n")
                    elif result['status'] in ['error', 'missing_original', 'missing_generated']:
                        f.write(f"é”™è¯¯ä¿¡æ¯: {result['error_message']}\n")
                    
                    f.write("-" * 50 + "\n")
            
            print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"\nâŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description='åˆ†æç”Ÿæˆçš„ .skel.json æ–‡ä»¶ä¸åŸå§‹ .json æ–‡ä»¶ä¹‹é—´çš„å·®å¼‚')
    parser.add_argument('--data-dir', default='../data',
                        help='åŒ…å« JSON æ–‡ä»¶çš„æ•°æ®ç›®å½• (é»˜è®¤: ../data)')
    parser.add_argument('--tolerance', '-t', type=float, default=0.10,
                        help='æ•°å€¼æ¯”è¾ƒç›¸å¯¹å®¹å·® (é»˜è®¤: 0.10ï¼Œå³10%%)')
    parser.add_argument('--abs-tolerance', '-a', type=float, default=0.01,
                        help='æ•°å€¼æ¯”è¾ƒç»å¯¹å®¹å·® (é»˜è®¤: 0.01)')
    parser.add_argument('--no-ignore-defaults', action='store_true',
                        help='ä¸å¿½ç•¥é»˜è®¤å€¼å·®å¼‚')
    parser.add_argument('--output', '-o',
                        help='ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶')
    
    args = parser.parse_args()
    
    try:
        analyzer = JsonDifferenceAnalyzer(
            data_dir=args.data_dir,
            tolerance=args.tolerance,
            abs_tolerance=args.abs_tolerance,
            ignore_defaults=not args.no_ignore_defaults
        )
        
        analyzer.analyze_all()
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        if args.output:
            analyzer.save_detailed_report(args.output)
        
        # è®¾ç½®é€€å‡ºç 
        if analyzer.stats['different_files'] > 0 or analyzer.stats['error_files'] > 0:
            sys.exit(1)
        else:
            sys.exit(0)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­åˆ†æè¿‡ç¨‹")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
